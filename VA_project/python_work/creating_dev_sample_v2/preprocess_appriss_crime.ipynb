{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# out = pd.read_csv('data/cf_apprissAppend_va2_10_17_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using python 3.8.10\n",
    "#imports \n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "column_names = ['source_id', \"popID\"]\n",
    "#here we are reading in our criminal data\n",
    "criminal_df = pd.read_csv(\"data/crime_cut_down_v1.csv\")\n",
    "NCIC_dic_df = pd.read_csv(\"data/diction_NCICcodes_descriptions_CrimeTiers_CDCTiers_as_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # before we turn crime file into flat file we need to cut down this list with our new confidence score as some of these people did are false matches to the crime data we received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_7588\\966273755.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  criminal_df['BookingChargeNCICOffenseCode'] = criminal_df['BookingChargeNCICOffenseCode'].str.replace('[', '')\n",
      "C:\\Users\\cayde\\AppData\\Local\\Temp\\ipykernel_7588\\966273755.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  criminal_df['BookingChargeNCICOffenseCode'] = criminal_df['BookingChargeNCICOffenseCode'].str.replace(']', '')\n"
     ]
    }
   ],
   "source": [
    "# remove the '[' and ']' from the NCIC code column\n",
    "criminal_df['BookingChargeNCICOffenseCode'] = criminal_df['BookingChargeNCICOffenseCode'].str.replace('[', '')\n",
    "criminal_df['BookingChargeNCICOffenseCode'] = criminal_df['BookingChargeNCICOffenseCode'].str.replace(']', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 ncic codes\n",
      "NCIC codes that never show up in dataset: 405\n",
      "NCIC codes that show up in dataset: 50\n"
     ]
    }
   ],
   "source": [
    "# here we will scan our data and remove any NCIC codes where we have no examples in the entire dataframe\n",
    "### this cuts down on the dimensions of the data frame from 1600x455 to 1600x52\n",
    "# here we are creating a subset of the raw data that has the CorrelationID, BookingDate, and unrolled NCICcodes per row\n",
    "# each rows unrolled NCIC offense codes\n",
    "unrolled_NCICCodes_df = criminal_df['BookingChargeNCICOffenseCode'].str.split(', ', expand=True)\n",
    "\n",
    "#pull the correlationId and bookingdate columns for the data set and join them to the unrolled NCIC codes\n",
    "unrolled_NCICCodes_df.insert(0, 'BookingDate', criminal_df['BookingDate'])\n",
    "unrolled_NCICCodes_df.insert(0, 'source_id', criminal_df['source_id'])\n",
    "unrolled_NCICCodes_df = unrolled_NCICCodes_df.fillna('')\n",
    "\n",
    "# here we are gonna make a distrobustion of counts of NCIC codes\n",
    "column_names_1 = ['NCICcode_count']\n",
    "index_names = []\n",
    "NCICcode_counts_df = pd.DataFrame(columns = column_names_1,)\n",
    "\n",
    "for index, row in NCIC_dic_df.iterrows():\n",
    "    if(row['NCIC Offense Code'] is not None and row['NCIC Offense Code'] != ''):\n",
    "        df = pd.DataFrame({\"NCICcode_count\":[0]})\n",
    "        NCICcode_counts_df = pd.concat([NCICcode_counts_df, df])\n",
    "        index_names.append(row['NCIC Offense Code'])\n",
    "\n",
    "NCICcode_counts_df = pd.DataFrame(NCICcode_counts_df).set_index([index_names])\n",
    "\n",
    "for ind, row in unrolled_NCICCodes_df.iterrows():\n",
    "    #print(row['CorrelationID'], row['BookingDate'], row[0])\n",
    "    # for i in range(0, 55):\n",
    "    for i in range(0, 48):\n",
    "        if(row[i] is not None and row[i] != ''):\n",
    "            NCICcode = int(row[i])\n",
    "            NCICcode_counts_df.at[NCICcode, 'NCICcode_count'] = NCICcode_counts_df.at[NCICcode, 'NCICcode_count'] + 1\n",
    "\n",
    "no_examples = []\n",
    "counter = 0\n",
    "for ind, row in NCICcode_counts_df.iterrows():\n",
    "    if(row['NCICcode_count'] == 0):\n",
    "        no_examples.append(row.name)\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "\n",
    "print(\"455 ncic codes\")\n",
    "print('NCIC codes that never show up in dataset: ' + str(len(no_examples)))\n",
    "print('NCIC codes that show up in dataset: ' + str(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are making the crime summary data frame\n",
    "for index, row in NCIC_dic_df.iterrows():\n",
    "    if(row['NCIC Offense Code'] not in no_examples):\n",
    "        if(row['NCIC Offense Code'] is not None and row['NCIC Offense Code'] != ''):\n",
    "            column_names.append(row['NCIC Offense Code'])\n",
    "\n",
    "criminalData_summary_df = pd.DataFrame(columns = column_names)\n",
    "unique_ids_column = criminal_df['source_id'].unique()\n",
    "\n",
    "\n",
    "for index in unique_ids_column:\n",
    "    df = pd.DataFrame({\"source_id\":[index]})\n",
    "    criminalData_summary_df = pd.concat([criminalData_summary_df, df])\n",
    "\n",
    "criminalData_summary_df = criminalData_summary_df.fillna(0)\n",
    "criminalData_summary_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# here we are adding a new columns for crimeTiers and CDCcats\n",
    "criminalData_summary_df = criminalData_summary_df.assign(tier_1=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(tier_2=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(tier_3=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(tier_4=0)\n",
    "\n",
    "criminalData_summary_df = criminalData_summary_df.assign(CDCcat_A=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(CDCcat_B=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(CDCcat_C=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(CDCcat_D=0)\n",
    "criminalData_summary_df = criminalData_summary_df.assign(CDCcat_E=0)\n",
    "\n",
    "# # here we are creating a subset of the raw data that has the CorrelationID, BookingDate, and unrolled NCICcodes per row\n",
    "# # each rows unrolled NCIC offense codes\n",
    "# unrolled_NCICCodes_df = criminal_df['BookingChargeNCICOffenseCode'].str.split(', ', expand=True)\n",
    "\n",
    "# #pull the correlationId and bookingdate columns for the data set and join them to the unrolled NCIC codes\n",
    "# unrolled_NCICCodes_df.insert(0, 'BookingDate', criminal_df['BookingDate'])\n",
    "# unrolled_NCICCodes_df.insert(0, 'CorrelationID', criminal_df['CorrelationID'])\n",
    "# unrolled_NCICCodes_df = unrolled_NCICCodes_df.fillna('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #here we build the dataset for alltime\n",
    "# master_dataset = criminalData_summary_df\n",
    "\n",
    "#This method is a simple check for handling tiers and crime cats. so gross ik but it works\n",
    "def check(val):\n",
    "    if(val == 1.0):\n",
    "        return \"tier_1\"\n",
    "    if(val == 2.0):\n",
    "        return \"tier_2\"\n",
    "    if(val == 3.0):\n",
    "        return \"tier_3\"\n",
    "    if(val == 4.0):\n",
    "        return \"tier_4\"\n",
    "    if(val == 'A'):\n",
    "        return \"CDCcat_A\"\n",
    "    if(val == 'B'):\n",
    "        return \"CDCcat_B\"\n",
    "    if(val == 'C'):\n",
    "        return \"CDCcat_C\"\n",
    "    if(val == 'D'):\n",
    "        return \"CDCcat_D\"\n",
    "    if(val == 'E'):\n",
    "        return \"CDCcat_E\"\n",
    "    if(val == None):\n",
    "        return None\n",
    "    if(val == 'NaN'):\n",
    "        return None\n",
    "\n",
    "\n",
    "# for ind, row in unrolled_NCICCodes_df.iterrows():\n",
    "#     for i in range(0, 55):\n",
    "#             if(row[i] is not None and row[i] != ''):\n",
    "#                 NCICcode = int(row[i])\n",
    "#                 summary_row = master_dataset[master_dataset['CorrelationID'] == row['CorrelationID']]\n",
    "#                 master_dataset.at[summary_row.index[0], NCICcode] = master_dataset.at[summary_row.index[0], NCICcode] +1\n",
    "#                 #this lower part handles both tiers and cdccat\n",
    "#                 TierVal = dict_df.at[NCICcode, \"Tier\"]\n",
    "#                 CDCcat_val = dict_df.at[NCICcode, \"CDC Category\"]\n",
    "#                 if(check(TierVal) != None):\n",
    "#                     master_dataset.at[summary_row.index[0], check(TierVal)] = master_dataset.at[summary_row.index[0], check(TierVal)] +1\n",
    "#                 if(check(CDCcat_val) != None):\n",
    "#                     master_dataset.at[summary_row.index[0], check(CDCcat_val)] = master_dataset.at[summary_row.index[0], check(CDCcat_val)] +1\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCIC Offense Code         int64\n",
      "Description of Crime     object\n",
      "Notes:                   object\n",
      "Tier                    float64\n",
      "CDC Category             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# what are the dtype for the columns of the dataframe NCIC_dic_df\n",
    "print(NCIC_dic_df.dtypes)\n",
    "\n",
    "# make NCIC Offense Code a the index of the dataframe\n",
    "NCIC_dic_df = NCIC_dic_df.set_index('NCIC Offense Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is where we actually genertae the values and put them into the dataset\n",
    "endDate_alltime = datetime(month=9,day=14,year=2021) # this is the last day of t0 for population 4\n",
    "\n",
    "#here we build the dataset for alltime\n",
    "master_dataset = criminalData_summary_df\n",
    "for ind, row in unrolled_NCICCodes_df.iterrows():\n",
    "    # for i in range(0, 55):\n",
    "    for i in range(0, 48):\n",
    "            if(row[i] is not None and row[i] != ''):\n",
    "                NCICcode = int(row[i])\n",
    "                summary_row = master_dataset[master_dataset['source_id'] == row['source_id']]\n",
    "                master_dataset.at[summary_row.index[0], NCICcode] = master_dataset.at[summary_row.index[0], NCICcode] +1\n",
    "                #this lower part handles both tiers and cdccat\n",
    "                TierVal = NCIC_dic_df.at[NCICcode, \"Tier\"]\n",
    "                CDCcat_val = NCIC_dic_df.at[NCICcode, \"CDC Category\"]\n",
    "                if(check(TierVal) != None):\n",
    "                    master_dataset.at[summary_row.index[0], check(TierVal)] = master_dataset.at[summary_row.index[0], check(TierVal)] +1\n",
    "                if(check(CDCcat_val) != None):\n",
    "                    master_dataset.at[summary_row.index[0], check(CDCcat_val)] = master_dataset.at[summary_row.index[0], check(CDCcat_val)] +1\n",
    "\n",
    "criminalData_summary_df = criminalData_summary_df.drop(['popID'],axis=1)\n",
    "\n",
    "# # # we need to build 7 datasets which are ALLtime and t0-t6\n",
    "# for j in range(0,7): # needs to be 0-6 = 7 but start with 0-1 =2. NOTE increasing this to 9 to cover t_mb6 and t_mb12\n",
    "#     dataset = criminalData_summary_df.copy()\n",
    "#     for ind, row in unrolled_NCICCodes_df.iterrows():\n",
    "#         BookingDate = datetime.strptime(row['BookingDate'], '%m/%d/%Y') # here is the booking date for each row\n",
    "#         if(isinstance(row['deathDate'], float)): #did not kill self\n",
    "#             endDate = endDate_alltime - pd.DateOffset(months=6 * j)\n",
    "#             startDate = endDate_alltime - pd.DateOffset(months=6 * (j + 1))\n",
    "#             # print('alive')\n",
    "#             # print(endDate)\n",
    "#             # print(startDate)\n",
    "#         else: # killed self\n",
    "#             deathDate = datetime.strptime(row['deathDate'], '%m/%d/%Y')\n",
    "#             endDate = deathDate - pd.DateOffset(months=6 * j)\n",
    "#             startDate = deathDate - pd.DateOffset(months=6 * (j + 1))\n",
    "#             # print(\"dead\")\n",
    "#             # print(row['deathDate'])\n",
    "#             # print(endDate)\n",
    "#             # print(startDate)\n",
    "#         if(j > 6):\n",
    "#             for i in range(0, 55):\n",
    "#                 if(row[i] is not None and row[i] != ''): # here is the case where we are in t0-t6 time\n",
    "#                     if(startDate <= BookingDate <= endDate):\n",
    "#                         NCICcode = int(row[i])\n",
    "#                         summary_row = dataset[dataset['CorrelationID'] == row['CorrelationID']]\n",
    "#                         dataset.at[summary_row.index[0], NCICcode] = dataset.at[summary_row.index[0], NCICcode] +1\n",
    "#                         #this lower part handles both tiers and cdccat\n",
    "#                         TierVal = dict_df.at[NCICcode, \"Tier\"]\n",
    "#                         CDCcat_val = dict_df.at[NCICcode, \"CDC Category\"]\n",
    "#                         if(check(TierVal) != None):\n",
    "#                             master_dataset.at[summary_row.index[0], check(TierVal)] = master_dataset.at[summary_row.index[0], check(TierVal)] +1\n",
    "#                         if(check(CDCcat_val) != None):\n",
    "#                             master_dataset.at[summary_row.index[0], check(CDCcat_val)] = master_dataset.at[summary_row.index[0], check(CDCcat_val)] +1\n",
    "#         if(j == 6):\n",
    "#             for i in range(0, 55):\n",
    "#                 if(row[i] is not None and row[i] != ''): # here is the case where we are in t0-t6 time\n",
    "#                     if(BookingDate <= endDate):\n",
    "#                         NCICcode = int(row[i])\n",
    "#                         summary_row = dataset[dataset['CorrelationID'] == row['CorrelationID']]\n",
    "#                         dataset.at[summary_row.index[0], NCICcode] = dataset.at[summary_row.index[0], NCICcode] +1\n",
    "#                         #this lower part handles both tiers and cdccat\n",
    "#                         TierVal = dict_df.at[NCICcode, \"Tier\"]\n",
    "#                         CDCcat_val = dict_df.at[NCICcode, \"CDC Category\"]\n",
    "#                         if(check(TierVal) != None):\n",
    "#                             master_dataset.at[summary_row.index[0], check(TierVal)] = master_dataset.at[summary_row.index[0], check(TierVal)] +1\n",
    "#                         if(check(CDCcat_val) != None):\n",
    "#                             master_dataset.at[summary_row.index[0], check(CDCcat_val)] = master_dataset.at[summary_row.index[0], check(CDCcat_val)] +1\n",
    "#     for col in dataset.columns:\n",
    "#         new_string = str(col) + \"_\" + \"t\" + str(j)\n",
    "#         if(col != \"CorrelationID\"):\n",
    "#             dataset.rename(columns={col:new_string},inplace=True)\n",
    "#     master_dataset = pd.merge(master_dataset, dataset, left_on= \"CorrelationID\", right_on='CorrelationID', how=\"outer\")\n",
    "\n",
    "# for j in range(1,3): # NOTE this is to cover t_mb6 and t_mb12\n",
    "#     dataset = criminalData_summary_df.copy()\n",
    "#     for ind, row in unrolled_NCICCodes_df.iterrows():\n",
    "#         BookingDate = datetime.strptime(row['BookingDate'], '%m/%d/%Y') # here is the booking date for each row\n",
    "#         if(isinstance(row['deathDate'], float)): #did not kill self\n",
    "#             endDate = endDate_alltime # death date does not shift in this one\n",
    "#             startDate = endDate_alltime - pd.DateOffset(months=6 * j)\n",
    "#         else: # killed self\n",
    "#             deathDate = datetime.strptime(row['deathDate'], '%m/%d/%Y')\n",
    "#             endDate = deathDate # death date does not shift in this one\n",
    "#             startDate = deathDate - pd.DateOffset(months=6 * j)\n",
    "#         for i in range(0, 55):\n",
    "#                 if(row[i] is not None and row[i] != ''): # here is the case where we are in t0-t6 time\n",
    "#                     if(BookingDate <= endDate):\n",
    "#                         NCICcode = int(row[i])\n",
    "#                         summary_row = dataset[dataset['CorrelationID'] == row['CorrelationID']]\n",
    "#                         dataset.at[summary_row.index[0], NCICcode] = dataset.at[summary_row.index[0], NCICcode] +1\n",
    "#                         #this lower part handles both tiers and cdccat\n",
    "#                         TierVal = dict_df.at[NCICcode, \"Tier\"]\n",
    "#                         CDCcat_val = dict_df.at[NCICcode, \"CDC Category\"]\n",
    "#                         if(check(TierVal) != None):\n",
    "#                             master_dataset.at[summary_row.index[0], check(TierVal)] = master_dataset.at[summary_row.index[0], check(TierVal)] +1\n",
    "#                         if(check(CDCcat_val) != None):\n",
    "#                             master_dataset.at[summary_row.index[0], check(CDCcat_val)] = master_dataset.at[summary_row.index[0], check(CDCcat_val)] +1\n",
    "#     for col in dataset.columns:\n",
    "#         new_string = str(col) + \"_\" + \"t_\" + str(j*6) + \"mb\"\n",
    "#         if(col != \"CorrelationID\"):\n",
    "#             dataset.rename(columns={col:new_string},inplace=True)\n",
    "#     master_dataset = pd.merge(master_dataset, dataset, left_on= \"CorrelationID\", right_on='CorrelationID', how=\"outer\")\n",
    "\n",
    "#here is how we fill in pop id\n",
    "#master_dataset.at[summary_row.index[0], 'popID'] = int(row['popID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are adding a new column to the end of the dataframe. this is all the crime data we have. Therefore each person in this summary has a criminal record. this is why we assign a value of 1 here. \n",
    "master_dataset = master_dataset.assign(HasCriminalRecord=1)\n",
    "\n",
    "# drop popID column\n",
    "master_dataset = master_dataset.drop(columns=['popID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every column in the dataframe, if the value of each row is non zero create a new column with the same name but with a 1 in it. this is to indicate that the person has a criminal record for that crime.\n",
    "for col in master_dataset.columns:\n",
    "    if(col != \"source_id\" and col != \"HasCriminalRecord\"):\n",
    "        master_dataset = master_dataset.assign(**{str(col) + \"_HasCrime\": master_dataset[col].apply(lambda x: 1 if x != 0 else 0)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "master_dataset.to_csv(\"data/out/appriss_crime_cleaned_CFconfidenceapplied_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1ebc6ce21e20a44ca2e939d468f8c4914f49f277b8be916293753b9e7a9feef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
